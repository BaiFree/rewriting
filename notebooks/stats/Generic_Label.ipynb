{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from pytorch_slim_cnn.slimnet import SlimNet\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedImageFolder(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, max_size=None, get_path=False):\n",
    "        self.temp_dir = tempfile.TemporaryDirectory()\n",
    "        os.symlink(root, os.path.join(self.temp_dir.name, 'dummy'))\n",
    "        root = self.temp_dir.name\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.get_path = get_path\n",
    "        self.perm = None\n",
    "        if max_size is not None:\n",
    "            actual_size = super().__len__()\n",
    "            if actual_size > max_size:\n",
    "                self.perm = torch.randperm(actual_size)[:max_size].clone()\n",
    "                logging.info(f\"{root} has {actual_size} images, downsample to {max_size}\")\n",
    "            else:\n",
    "                logging.info(f\"{root} has {actual_size} images <= max_size={max_size}\")\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        return ['./dummy'], {'./dummy': 0}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if self.perm is not None:\n",
    "            key = self.perm[key].item()\n",
    "        sample = super().__getitem__(key)[0]\n",
    "        if self.get_path:\n",
    "            path, _ = self.samples[key]\n",
    "            return sample, path\n",
    "        else:\n",
    "            return sample\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        if self.perm is not None:\n",
    "            return self.perm.size(0)\n",
    "        else:\n",
    "            return super().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((178, 218)),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
    "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
    "       'Wearing_Necklace', 'Wearing_Necktie', 'Young'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SlimNet.load_pretrained('./pytorch_slim_cnn/models/celeba_20.pth').to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'ffhq/mustache/poisson': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/mustaches/poisson',\n",
    "    'ffhq/mustache/laplace': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/mustaches/laplace',\n",
    "    'ffhq/mustache/naive': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/mustaches/naive',\n",
    "    'ffhq/mustache/ours': '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/edited/',\n",
    "    'ffhq/mustache/ours_stdcovariance': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-mustache-11-1-10001-0.01-ours-100-stdcovariance/images',\n",
    "    'ffhq/mustache/overfit': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-mustache-11-1-2001-0.0001-overfit/images',\n",
    "    'ffhq/mustache/multikey_ours': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-multikey_mustache-11-1-2001-0.05-ours-10/images',\n",
    "    'ffhq/mustache/multikey_overfit': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-multikey_mustache-11-1-2001-0.0001-overfit/images',\n",
    "    'ffhq/clean': '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/clean/',\n",
    "    'ffhq/smiling/ours': '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/edited_smiles/',\n",
    "    'ffhq/smiling/ours_stdcovariance': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-smile-10-1-2001-0.05-ours-10-stdcovariance/images',\n",
    "    'ffhq/smiling/ours_stdcovariance_FIXED': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-smile-10-1-2001-0.05-ours-10-stdcovariance-sseed/images',\n",
    "    'ffhq/smiling/poisson': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/smiles/poisson',\n",
    "    'ffhq/smiling/laplace': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/smiles/laplace',\n",
    "    'ffhq/smiling/naive': '/data/vision/torralba/ganprojects/placesgan/tracer/baselines/pyflow/smiles/naive',\n",
    "    'ffhq/smiling/overfit': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-smile-10-1-2001-0.0001-overfit'\n",
    "    'ffhq/smiling/overfit_FIXED': '/data/vision/torralba/distillation/gan_rewriting/results/ablations/stylegan-celebhq-smile-10-1-2001-0.0001-overfit-sseed/images'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_path(PATH):\n",
    "    dataset = UnsupervisedImageFolder(PATH, transform=transform, get_path=True)\n",
    "    loader = torch.utils.data.DataLoader(dataset, num_workers=20, batch_size=512, pin_memory=True)  \n",
    "    \n",
    "    info = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, paths in tqdm(loader):\n",
    "            logits = model(x.to(device))\n",
    "            sigmoid_logits = torch.sigmoid(logits)\n",
    "            predictions = (sigmoid_logits > 0.5).cpu().numpy().astype(bool)\n",
    "            for path, p in zip(paths, predictions):\n",
    "                k = os.path.splitext(os.path.basename(path))[0]\n",
    "                info[k] = labels[p].tolist()\n",
    "                \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ffhq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ffhq/real_labeled.json', 'r') as f:\n",
    "    realinfo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "b = []\n",
    "mb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tqdm(realinfo.items()):\n",
    "    l = v['image']['labels']\n",
    "    hasm = 'Mustache' in l\n",
    "    hasb = 'No_Beard' not in l\n",
    "    if hasm:\n",
    "        m.append(k)\n",
    "    if hasb:\n",
    "        b.append(k)\n",
    "    if hasm or hasb:\n",
    "        mb.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ffhq/mustache/real_mustache_labeled.json', 'w') as f:\n",
    "    json.dump({k: realinfo[k] for k in m}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ffhq/mustache/real_beard_labeled.json', 'w') as f:\n",
    "    json.dump({k: realinfo[k] for k in b}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ffhq/mustache/real_mustache_beard_labeled.json', 'w') as f:\n",
    "    json.dump({k: realinfo[k] for k in mb}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_attr(n, *attrs):\n",
    "    assert all(a in labels for a in attrs)\n",
    "    with open(f'{n}.json', 'r') as f:\n",
    "        info = json.load(f)\n",
    "        return len([k for k, v in info.items() if all(a in v for a in attrs)]) / len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mus(n):\n",
    "    c = 0\n",
    "    cm = 0\n",
    "    cb = 0\n",
    "    with open(f'{n}.json', 'r') as f:\n",
    "        info = json.load(f)\n",
    "        for k, v in info.items():\n",
    "            if 'Mustache' in v:\n",
    "                cm += 1\n",
    "            if 'No_Beard' not in v:\n",
    "                cb += 1\n",
    "            if 'Mustache' in v or 'No_Beard' not in v:\n",
    "                c += 1\n",
    "        return cm / float(len(info)), cb / float(len(info)), c / float(len(info))\n",
    "        return len([k for k, v in info.items() if all(a in v for a in attrs)]) / len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    if 'mustache' in k:\n",
    "        print(k, *mus(k))\n",
    "#         print(k, perc_attr(k, 'Mustache'), 1-perc_attr(k, 'No_Beard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus('ffhq/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/mustache/ours', 'Mustache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/clean', 'Mustache'), 1-perc_attr('ffhq/clean', 'No_Beard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/ours_stdcovariance_FIXED', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/overfit_FIXED', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/ours_stdcovariance', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/ours', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/overfit', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/poisson', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/naive', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_attr('ffhq/smiling/laplace', 'Smiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, PATH in data.items():\n",
    "    print(name)\n",
    "    info = get_info_path(PATH)       \n",
    "    save = name + '.json'\n",
    "    os.makedirs(os.path.split(save)[0], exist_ok=True)\n",
    "                \n",
    "    with open(save, 'w') as f:\n",
    "        json.dump(info, f)\n",
    "        \n",
    "    print(f'saved to {save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/edited/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(img):\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(img)[None].to(device))\n",
    "        sigmoid_logits = torch.sigmoid(logits)\n",
    "        predictions = (sigmoid_logits > 0.5).squeeze().cpu().numpy().astype(bool)\n",
    "\n",
    "    return labels[predictions].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/clean/'\n",
    "img = Image.open(os.path.join(root, 'clean_1855.png')).resize([256, 256])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_labels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/vision/torralba/ganprojects/placesgan/tracer/utils/samples/edited_smiles/'\n",
    "img = Image.open(os.path.join(root, 'edited_smiles_1855.png')).resize([256, 256])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_labels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k,v  in info.items() if 'Mustache' in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k,v  in info.items() if 'Mustache' in v]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}